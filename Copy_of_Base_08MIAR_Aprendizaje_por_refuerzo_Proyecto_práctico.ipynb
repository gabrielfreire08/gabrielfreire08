{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Base - 08MIAR Aprendizaje por refuerzo - Proyecto práctico.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielfreire08/gabrielfreire08/blob/main/Copy_of_Base_08MIAR_Aprendizaje_por_refuerzo_Proyecto_pr%C3%A1ctico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX95X2zBKyzW"
      },
      "source": [
        "### Proyecto práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk0Ok-hAKyzZ"
      },
      "source": [
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, una solución óptima será alcanzada cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v8pAUZGKyzb"
      },
      "source": [
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "   1) Implementar la red neuronal que se usará en la solución\n",
        "    \n",
        "   2) Implementar las distintas piezas de la solución DQN\n",
        "    \n",
        "   3) Justificar la respuesta en relación a los resultados obtenidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkSBr0nyKyzc"
      },
      "source": [
        "IMPORTANTE:\n",
        "\n",
        "- Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "\n",
        "- Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "\n",
        "- Tened en cuenta que las versiones de librerías recomendadas son Tensorflow==1.13.1, Keras==2.2.4 y keras-rl==0.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUZR_2c0l-Io"
      },
      "source": [
        "# 0) Configuraciones y carga de entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz6QFmIMmIgW"
      },
      "source": [
        "## Instalar los módulos necesarios para el proyecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIF6tPusg0Mj",
        "outputId": "2bab8282-4810-466d-807a-a07767cb33a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPz9EYilKyzc"
      },
      "source": [
        "%%capture\n",
        "!pip install gym==0.17.3\n",
        "!pip install h5py==2.10.0\n",
        "!pip install Pillow\n",
        "!pip install gym[atari]\n",
        "!pip install keras-rl==0.4.2\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install keras==2.2.4\n",
        "!pip install jupyter\n",
        "!pip install torch\n",
        "!pip freeze"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "byGQwaEuLU9j",
        "outputId": "32567ef6-fb0f-426a-8290-5015dead408d"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPDj01-ZKyze"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz2J7lznKyze"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, Nadam\n",
        "import keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXGVm06dKyzf"
      },
      "source": [
        "## Cargar el entorno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LANHlVYLhNc"
      },
      "source": [
        "%%capture\n",
        "# Vamos a descargar el rom del juego\n",
        "! wget http://www.atarimania.com/roms/Roms.rar\n",
        "! mkdir /content/ROM/\n",
        "! unrar e /content/Roms.rar /content/ROM/\n",
        "! python -m atari_py.import_roms /content/ROM/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsbPIEa-WG6-"
      },
      "source": [
        "Cargaremos algunos utilitarios para que nos faciliten la visualización del juego en Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-teQUDjfSLLH"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRbfzC9vSvNT",
        "outputId": "6c142d2b-e847-401e-9d53-294c73cc6c01"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f9bef536c50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MgdwYQi0S0tH",
        "outputId": "4bd14b9a-0ff7-444c-b464-15c2d8ed3ef2"
      },
      "source": [
        "# Cargamos el entorno del juego\n",
        "env = gym.make(\"SpaceInvaders-v0\")\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "# Hacemos una previsualización aleatoria de frames\n",
        "for i in range(50):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  \n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "    \n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKqaOUaenxf"
      },
      "source": [
        "Cargamos el entorno del juego, en este caso SpaceInvaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9QgbNgwejpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d50af71-26b2-46ca-ea98-bb7113191702"
      },
      "source": [
        "env = gym.make('SpaceInvaders-v0')\n",
        "height, width, channels = env.observation_space.shape\n",
        "actions = env.action_space.n\n",
        "print(f\"Acciones que puede tomar: {env.unwrapped.get_action_meanings()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acciones que puede tomar: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQSGEbNDVh7A"
      },
      "source": [
        "Veamos las acciones que tiene disponible el agente. Tenemos 6 acciones:\n",
        "* No hacer nada\n",
        "* Disparar\n",
        "* Moverse a la izquierda\n",
        "* Moverse a la derecha\n",
        "* Moverse a la izquierda y disparar\n",
        "* Moverse a la derecha y disparar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq2Dlmk8OfXe",
        "outputId": "ffe24020-6e23-4310-ce81-b7141b0c0a60"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNqJWn1-UsDD",
        "outputId": "022997a4-3d4c-46ae-bf95-55ac5189fc6a"
      },
      "source": [
        "env.env.get_action_meanings()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fn-YSlp5By8"
      },
      "source": [
        "# Vamos a trabajar con un tamaño de frame más pequeño\n",
        "# para que sea más manejable sin perder la proporción\n",
        "INPUT_SHAPE=(88,80)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMdvh-oCeW38"
      },
      "source": [
        "Aquí estamos probando como se comportaría el juego si lo dejamos que tome acciones aleatorias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R2suD3CeV2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fa24ce-de9e-4cda-c802-329d721335f9"
      },
      "source": [
        "episodes = 5\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = random.choice([0,1,2,3,4,5])\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:30.0\n",
            "Episode:2 Score:85.0\n",
            "Episode:3 Score:80.0\n",
            "Episode:4 Score:285.0\n",
            "Episode:5 Score:35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDw4fekUokUa"
      },
      "source": [
        "## Pre-procesado de Frames y Procesador Atari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PknEMNf0nGS9"
      },
      "source": [
        "Vamos a implementar una función de pre-procesado de frames para asegurar un nivel de análisis de patrones por parte de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBiBcix-2T49"
      },
      "source": [
        "color = np.array([210, 164, 74]).mean()\n",
        "\n",
        "def preprocess_frame(obs):\n",
        "    # Cortaremos la parte \"jugable\" (sin el marcador) y reduciremos el número de canales\n",
        "    img = obs[25:201:2, ::2]\n",
        "\n",
        "    # Convertimos a escala de grises\n",
        "    img = img.mean(axis=2)\n",
        "\n",
        "    # Mejoramos el contraste\n",
        "    img[img==color] = 0\n",
        "\n",
        "    # Normalizamos la imagen\n",
        "    img = (img - 128) / 128 - 1\n",
        "\n",
        "    # Rescalamos la imagen a 88*80*1\n",
        "    img = img.reshape(88,80)\n",
        "\n",
        "    return img "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ggV_4zbh2mZL",
        "outputId": "cbef0563-851d-42fb-b063-f7acd82a9cd5"
      },
      "source": [
        "observation = env.reset()\n",
        "# Veamos como era la imagen original\n",
        "for i in range(11):\n",
        "  if i > 9:\n",
        "    plt.imshow(observation)\n",
        "    plt.title(\"Imagen Original\")\n",
        "    plt.show()\n",
        "  observation, _, _, _ = env.step(1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "XRWmQnDF2n1I",
        "outputId": "f5be7160-c7e2-4f2a-ee81-0c0a924f9b4a"
      },
      "source": [
        "# Preprocessed Game Screen\n",
        "obs_preprocesado = preprocess_frame(observation)\n",
        "plt.imshow(obs_preprocesado)\n",
        "plt.title(\"Imagen Preprocesada\")\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3YIMNgcovIo"
      },
      "source": [
        "Ahora, lo último que tenemos que hacer en esta sección es implementar el preprocesado dentro de nuestro procesador Atari."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLLqWXnz3B36"
      },
      "source": [
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        img = preprocess_frame(observation)\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zoZLdbfpF8y"
      },
      "source": [
        "# 1) Implementar la red neuronal de la solución\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6GR3IId4EOC",
        "outputId": "aa8e61a3-8791-4dce-d08d-79a742c87c20"
      },
      "source": [
        "# Definimos nuestro modelo de red neuronal. \n",
        "# Usaremos como base el modelo del artículo de Mnih et al. (2015).\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
        "# Bloque convolucional\n",
        "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
        "model.add(Activation('relu'))\n",
        "# Top model\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "permute_1 (Permute)          (None, 88, 80, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 19, 32)        8224      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 21, 19, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 8, 64)          32832     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 9, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 7, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2688)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1376768   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 3078      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 1,457,830\n",
            "Trainable params: 1,457,830\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmW1LuFIp2YN"
      },
      "source": [
        "# 2) Implementar las distintas piezas de la solución DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nf83J9-qIhL"
      },
      "source": [
        "## Definir el tamaño de memoria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSHi_nZmqP4L"
      },
      "source": [
        "Para el proyecto vamos a usar una memoria de 1000000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B14hyyTC4Rvb"
      },
      "source": [
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "processor = AtariProcessor()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8T5SG_zqYYz"
      },
      "source": [
        "## Definir la estrategia o policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpEuHtrcqtgy"
      },
      "source": [
        "Definiremos nuestra policy como una EpsilonGreedyQPolicy, con un valor epsilon mínimo de 0.1 y uno máximo de 1. La variación será por 1000000 de steps (que coincide con el número de steps que vamos a usar en el entrenamiento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypDR8M2A4YfU"
      },
      "source": [
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1., value_min=.1, value_test=.05,\n",
        "                              nb_steps=1000000)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0OQyM0rakH"
      },
      "source": [
        "## Configurar agente DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToU-Mxq1rilH"
      },
      "source": [
        "Configuramos nuestro modelo, número de acciones, política y memoria previamente definidos. Definiremos un calentamiento de 50000 steps en el cual el modelo no actualizará nada, nuestro gamma o discount rate tendrá un valor de 0.99 para darle mucha importancia a las recompensas de estados previos. Nuestro modelo se actualizará cada 10000 steps y el intervalo de entrenamiento lo definiremos en 6 acciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yfelQlt4d4b"
      },
      "source": [
        "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
        "               memory=memory, processor=processor,\n",
        "               nb_steps_warmup=50000, gamma=.99,\n",
        "               target_model_update=10000,\n",
        "               train_interval=30)\n",
        "\n",
        "# Usaremos un optimizador Nadam con learning rate de 0.003.\n",
        "#dqn.compile(Nadam(lr=.003), metrics=['mse'])\n",
        "dqn.compile(Adam(lr=.00025), metrics=['mae'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppxB6W8Ds0Fs"
      },
      "source": [
        "# Entrenamiento del agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJcnECr04jFj",
        "outputId": "d3bc954a-bf95-42b0-b76d-97aedcfa7682"
      },
      "source": [
        "# Configuramos los callbacks que vamos a necesitar\n",
        "weights_filename = '/content/drive/MyDrive/ProyectoRL/dqn_{}_weights.h5'.format(env_name)\n",
        "checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5'\n",
        "log_filename = 'dqn_{}_log.json'.format(env_name)\n",
        "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
        "callbacks += [FileLogger(log_filename, interval=100)]\n",
        "\n",
        "# Iniciamos el entrenamiento del agente\n",
        "dqn.fit(env, callbacks=callbacks, nb_steps=1750000, log_interval=10000, visualize=False)\n",
        "\n",
        "# Guardamos los pesos\n",
        "dqn.save_weights(weights_filename, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 1750000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "10000/10000 [==============================] - 39s 4ms/step - reward: 0.0128\n",
            "14 episodes - episode_reward: 9.071 [4.000, 16.000] - ale.lives: 2.176\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 39s 4ms/step - reward: 0.0121\n",
            "12 episodes - episode_reward: 9.833 [4.000, 12.000] - ale.lives: 2.109\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 39s 4ms/step - reward: 0.0130\n",
            "15 episodes - episode_reward: 8.133 [4.000, 14.000] - ale.lives: 1.989\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 39s 4ms/step - reward: 0.0125\n",
            "14 episodes - episode_reward: 9.214 [3.000, 19.000] - ale.lives: 2.184\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 39s 4ms/step - reward: 0.0119\n",
            "17 episodes - episode_reward: 7.294 [2.000, 13.000] - ale.lives: 2.193\n",
            "\n",
            "Interval 6 (50000 steps performed)\n",
            "    1/10000 [..............................] - ETA: 3:00 - reward: 0.0000e+00WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "10000/10000 [==============================] - 90s 9ms/step - reward: 0.0148\n",
            "15 episodes - episode_reward: 10.000 [3.000, 26.000] - loss: 0.007 - mean_absolute_error: 0.019 - mean_q: 0.018 - mean_eps: 0.951 - ale.lives: 2.116\n",
            "\n",
            "Interval 7 (60000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0148\n",
            "14 episodes - episode_reward: 10.571 [6.000, 18.000] - loss: 0.006 - mean_absolute_error: 0.009 - mean_q: -0.001 - mean_eps: 0.942 - ale.lives: 2.087\n",
            "\n",
            "Interval 8 (70000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0137\n",
            "13 episodes - episode_reward: 10.077 [3.000, 22.000] - loss: 0.006 - mean_absolute_error: 0.010 - mean_q: 0.012 - mean_eps: 0.932 - ale.lives: 2.177\n",
            "\n",
            "Interval 9 (80000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0141\n",
            "14 episodes - episode_reward: 10.357 [4.000, 21.000] - loss: 0.006 - mean_absolute_error: 0.023 - mean_q: 0.027 - mean_eps: 0.924 - ale.lives: 1.998\n",
            "\n",
            "Interval 10 (90000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0129\n",
            "12 episodes - episode_reward: 10.667 [4.000, 19.000] - loss: 0.006 - mean_absolute_error: 0.036 - mean_q: 0.044 - mean_eps: 0.915 - ale.lives: 2.007\n",
            "\n",
            "Interval 11 (100000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0121\n",
            "16 episodes - episode_reward: 7.812 [3.000, 17.000] - loss: 0.006 - mean_absolute_error: 0.051 - mean_q: 0.063 - mean_eps: 0.906 - ale.lives: 2.133\n",
            "\n",
            "Interval 12 (110000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0133\n",
            "13 episodes - episode_reward: 9.385 [4.000, 18.000] - loss: 0.007 - mean_absolute_error: 0.061 - mean_q: 0.076 - mean_eps: 0.897 - ale.lives: 2.293\n",
            "\n",
            "Interval 13 (120000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0150\n",
            "13 episodes - episode_reward: 10.769 [3.000, 21.000] - loss: 0.007 - mean_absolute_error: 0.071 - mean_q: 0.087 - mean_eps: 0.888 - ale.lives: 2.131\n",
            "\n",
            "Interval 14 (130000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0132\n",
            "15 episodes - episode_reward: 9.933 [3.000, 21.000] - loss: 0.007 - mean_absolute_error: 0.082 - mean_q: 0.101 - mean_eps: 0.879 - ale.lives: 2.048\n",
            "\n",
            "Interval 15 (140000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0173\n",
            "11 episodes - episode_reward: 14.818 [7.000, 27.000] - loss: 0.007 - mean_absolute_error: 0.099 - mean_q: 0.122 - mean_eps: 0.870 - ale.lives: 2.231\n",
            "\n",
            "Interval 16 (150000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0149\n",
            "14 episodes - episode_reward: 10.714 [6.000, 20.000] - loss: 0.007 - mean_absolute_error: 0.106 - mean_q: 0.130 - mean_eps: 0.861 - ale.lives: 2.000\n",
            "\n",
            "Interval 17 (160000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0187\n",
            "12 episodes - episode_reward: 16.250 [4.000, 40.000] - loss: 0.007 - mean_absolute_error: 0.119 - mean_q: 0.146 - mean_eps: 0.852 - ale.lives: 2.081\n",
            "\n",
            "Interval 18 (170000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0121\n",
            "13 episodes - episode_reward: 8.769 [1.000, 17.000] - loss: 0.006 - mean_absolute_error: 0.124 - mean_q: 0.152 - mean_eps: 0.843 - ale.lives: 1.954\n",
            "\n",
            "Interval 19 (180000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0142\n",
            "16 episodes - episode_reward: 9.250 [3.000, 15.000] - loss: 0.008 - mean_absolute_error: 0.141 - mean_q: 0.172 - mean_eps: 0.834 - ale.lives: 2.220\n",
            "\n",
            "Interval 20 (190000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0161\n",
            "15 episodes - episode_reward: 10.667 [1.000, 26.000] - loss: 0.008 - mean_absolute_error: 0.156 - mean_q: 0.189 - mean_eps: 0.825 - ale.lives: 1.975\n",
            "\n",
            "Interval 21 (200000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0136\n",
            "14 episodes - episode_reward: 10.000 [4.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.170 - mean_q: 0.205 - mean_eps: 0.816 - ale.lives: 2.053\n",
            "\n",
            "Interval 22 (210000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0135\n",
            "15 episodes - episode_reward: 8.933 [3.000, 17.000] - loss: 0.007 - mean_absolute_error: 0.181 - mean_q: 0.218 - mean_eps: 0.807 - ale.lives: 1.961\n",
            "\n",
            "Interval 23 (220000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0139\n",
            "13 episodes - episode_reward: 11.000 [4.000, 19.000] - loss: 0.007 - mean_absolute_error: 0.198 - mean_q: 0.239 - mean_eps: 0.798 - ale.lives: 2.119\n",
            "\n",
            "Interval 24 (230000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0152\n",
            "13 episodes - episode_reward: 10.692 [3.000, 22.000] - loss: 0.008 - mean_absolute_error: 0.220 - mean_q: 0.266 - mean_eps: 0.789 - ale.lives: 2.098\n",
            "\n",
            "Interval 25 (240000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0153\n",
            "19 episodes - episode_reward: 8.737 [2.000, 23.000] - loss: 0.006 - mean_absolute_error: 0.230 - mean_q: 0.278 - mean_eps: 0.780 - ale.lives: 2.149\n",
            "\n",
            "Interval 26 (250000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0157\n",
            "12 episodes - episode_reward: 12.417 [5.000, 27.000] - loss: 0.007 - mean_absolute_error: 0.246 - mean_q: 0.301 - mean_eps: 0.770 - ale.lives: 2.137\n",
            "\n",
            "Interval 27 (260000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0147\n",
            "11 episodes - episode_reward: 12.545 [6.000, 22.000] - loss: 0.007 - mean_absolute_error: 0.242 - mean_q: 0.293 - mean_eps: 0.762 - ale.lives: 1.965\n",
            "\n",
            "Interval 28 (270000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0147\n",
            "14 episodes - episode_reward: 11.429 [3.000, 23.000] - loss: 0.007 - mean_absolute_error: 0.255 - mean_q: 0.308 - mean_eps: 0.753 - ale.lives: 1.914\n",
            "\n",
            "Interval 29 (280000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0139\n",
            "16 episodes - episode_reward: 8.812 [2.000, 16.000] - loss: 0.007 - mean_absolute_error: 0.264 - mean_q: 0.320 - mean_eps: 0.743 - ale.lives: 2.106\n",
            "\n",
            "Interval 30 (290000 steps performed)\n",
            "10000/10000 [==============================] - 90s 9ms/step - reward: 0.0176\n",
            "13 episodes - episode_reward: 13.462 [2.000, 26.000] - loss: 0.007 - mean_absolute_error: 0.267 - mean_q: 0.323 - mean_eps: 0.735 - ale.lives: 2.038\n",
            "\n",
            "Interval 31 (300000 steps performed)\n",
            "10000/10000 [==============================] - 90s 9ms/step - reward: 0.0158\n",
            "13 episodes - episode_reward: 12.308 [5.000, 30.000] - loss: 0.007 - mean_absolute_error: 0.277 - mean_q: 0.335 - mean_eps: 0.726 - ale.lives: 1.993\n",
            "\n",
            "Interval 32 (310000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0163\n",
            "13 episodes - episode_reward: 12.154 [2.000, 26.000] - loss: 0.007 - mean_absolute_error: 0.292 - mean_q: 0.354 - mean_eps: 0.716 - ale.lives: 1.962\n",
            "\n",
            "Interval 33 (320000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0143\n",
            "12 episodes - episode_reward: 12.333 [5.000, 24.000] - loss: 0.008 - mean_absolute_error: 0.298 - mean_q: 0.360 - mean_eps: 0.708 - ale.lives: 2.047\n",
            "\n",
            "Interval 34 (330000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0159\n",
            "14 episodes - episode_reward: 11.429 [4.000, 22.000] - loss: 0.007 - mean_absolute_error: 0.303 - mean_q: 0.366 - mean_eps: 0.699 - ale.lives: 2.098\n",
            "\n",
            "Interval 35 (340000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0154\n",
            "14 episodes - episode_reward: 10.643 [3.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.317 - mean_q: 0.383 - mean_eps: 0.690 - ale.lives: 2.088\n",
            "\n",
            "Interval 36 (350000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0150\n",
            "13 episodes - episode_reward: 11.462 [5.000, 21.000] - loss: 0.009 - mean_absolute_error: 0.324 - mean_q: 0.390 - mean_eps: 0.681 - ale.lives: 2.036\n",
            "\n",
            "Interval 37 (360000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0142\n",
            "13 episodes - episode_reward: 10.923 [6.000, 23.000] - loss: 0.007 - mean_absolute_error: 0.329 - mean_q: 0.398 - mean_eps: 0.672 - ale.lives: 2.074\n",
            "\n",
            "Interval 38 (370000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0149\n",
            "13 episodes - episode_reward: 11.462 [4.000, 16.000] - loss: 0.007 - mean_absolute_error: 0.343 - mean_q: 0.413 - mean_eps: 0.662 - ale.lives: 2.102\n",
            "\n",
            "Interval 39 (380000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0153\n",
            "14 episodes - episode_reward: 10.857 [5.000, 17.000] - loss: 0.007 - mean_absolute_error: 0.355 - mean_q: 0.428 - mean_eps: 0.654 - ale.lives: 2.053\n",
            "\n",
            "Interval 40 (390000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0154\n",
            "14 episodes - episode_reward: 11.357 [6.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.361 - mean_q: 0.434 - mean_eps: 0.645 - ale.lives: 2.008\n",
            "\n",
            "Interval 41 (400000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0139\n",
            "12 episodes - episode_reward: 11.083 [5.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.369 - mean_q: 0.446 - mean_eps: 0.635 - ale.lives: 2.075\n",
            "\n",
            "Interval 42 (410000 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 0.0151\n",
            "14 episodes - episode_reward: 10.857 [5.000, 19.000] - loss: 0.007 - mean_absolute_error: 0.377 - mean_q: 0.456 - mean_eps: 0.627 - ale.lives: 2.120\n",
            "\n",
            "Interval 43 (420000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0164\n",
            "16 episodes - episode_reward: 10.625 [2.000, 20.000] - loss: 0.007 - mean_absolute_error: 0.376 - mean_q: 0.454 - mean_eps: 0.618 - ale.lives: 2.096\n",
            "\n",
            "Interval 44 (430000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0144\n",
            "11 episodes - episode_reward: 12.636 [8.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.387 - mean_q: 0.469 - mean_eps: 0.608 - ale.lives: 2.000\n",
            "\n",
            "Interval 45 (440000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0137\n",
            "11 episodes - episode_reward: 12.091 [3.000, 19.000] - loss: 0.006 - mean_absolute_error: 0.399 - mean_q: 0.484 - mean_eps: 0.600 - ale.lives: 1.931\n",
            "\n",
            "Interval 46 (450000 steps performed)\n",
            "10000/10000 [==============================] - 109s 11ms/step - reward: 0.0156\n",
            "14 episodes - episode_reward: 11.357 [4.000, 26.000] - loss: 0.007 - mean_absolute_error: 0.412 - mean_q: 0.499 - mean_eps: 0.591 - ale.lives: 1.965\n",
            "\n",
            "Interval 47 (460000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0146\n",
            "13 episodes - episode_reward: 11.308 [5.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.413 - mean_q: 0.499 - mean_eps: 0.582 - ale.lives: 2.024\n",
            "\n",
            "Interval 48 (470000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0136\n",
            "14 episodes - episode_reward: 10.143 [5.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.432 - mean_q: 0.523 - mean_eps: 0.573 - ale.lives: 2.041\n",
            "\n",
            "Interval 49 (480000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0133\n",
            "12 episodes - episode_reward: 10.583 [3.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.449 - mean_q: 0.543 - mean_eps: 0.564 - ale.lives: 1.957\n",
            "\n",
            "Interval 50 (490000 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 0.0166\n",
            "12 episodes - episode_reward: 14.000 [7.000, 21.000] - loss: 0.007 - mean_absolute_error: 0.451 - mean_q: 0.546 - mean_eps: 0.554 - ale.lives: 2.078\n",
            "\n",
            "Interval 51 (500000 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 0.0154\n",
            "13 episodes - episode_reward: 11.769 [2.000, 28.000] - loss: 0.007 - mean_absolute_error: 0.460 - mean_q: 0.556 - mean_eps: 0.546 - ale.lives: 2.102\n",
            "\n",
            "Interval 52 (510000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0138\n",
            "11 episodes - episode_reward: 11.636 [3.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.473 - mean_q: 0.569 - mean_eps: 0.537 - ale.lives: 1.966\n",
            "\n",
            "Interval 53 (520000 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 0.0155\n",
            "15 episodes - episode_reward: 11.333 [2.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.477 - mean_q: 0.575 - mean_eps: 0.527 - ale.lives: 2.009\n",
            "\n",
            "Interval 54 (530000 steps performed)\n",
            "10000/10000 [==============================] - 100s 10ms/step - reward: 0.0144\n",
            "13 episodes - episode_reward: 10.000 [4.000, 27.000] - loss: 0.008 - mean_absolute_error: 0.482 - mean_q: 0.581 - mean_eps: 0.519 - ale.lives: 2.019\n",
            "\n",
            "Interval 55 (540000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0145\n",
            "14 episodes - episode_reward: 10.786 [4.000, 24.000] - loss: 0.007 - mean_absolute_error: 0.488 - mean_q: 0.589 - mean_eps: 0.510 - ale.lives: 2.070\n",
            "\n",
            "Interval 56 (550000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0158\n",
            "14 episodes - episode_reward: 10.500 [1.000, 19.000] - loss: 0.006 - mean_absolute_error: 0.494 - mean_q: 0.597 - mean_eps: 0.500 - ale.lives: 1.947\n",
            "\n",
            "Interval 57 (560000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0144\n",
            "11 episodes - episode_reward: 13.364 [5.000, 24.000] - loss: 0.008 - mean_absolute_error: 0.495 - mean_q: 0.596 - mean_eps: 0.492 - ale.lives: 1.953\n",
            "\n",
            "Interval 58 (570000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0180\n",
            "14 episodes - episode_reward: 13.571 [6.000, 24.000] - loss: 0.008 - mean_absolute_error: 0.500 - mean_q: 0.602 - mean_eps: 0.483 - ale.lives: 2.016\n",
            "\n",
            "Interval 59 (580000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0116\n",
            "10 episodes - episode_reward: 11.300 [3.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.499 - mean_q: 0.601 - mean_eps: 0.474 - ale.lives: 1.858\n",
            "\n",
            "Interval 60 (590000 steps performed)\n",
            "10000/10000 [==============================] - 100s 10ms/step - reward: 0.0150\n",
            "12 episodes - episode_reward: 12.000 [7.000, 16.000] - loss: 0.008 - mean_absolute_error: 0.512 - mean_q: 0.621 - mean_eps: 0.465 - ale.lives: 2.047\n",
            "\n",
            "Interval 61 (600000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0148\n",
            "14 episodes - episode_reward: 11.286 [6.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.525 - mean_q: 0.634 - mean_eps: 0.456 - ale.lives: 2.070\n",
            "\n",
            "Interval 62 (610000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0130\n",
            "15 episodes - episode_reward: 8.467 [3.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.520 - mean_q: 0.626 - mean_eps: 0.447 - ale.lives: 1.969\n",
            "\n",
            "Interval 63 (620000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0154\n",
            "11 episodes - episode_reward: 13.273 [5.000, 23.000] - loss: 0.007 - mean_absolute_error: 0.524 - mean_q: 0.633 - mean_eps: 0.438 - ale.lives: 2.039\n",
            "\n",
            "Interval 64 (630000 steps performed)\n",
            "10000/10000 [==============================] - 108s 11ms/step - reward: 0.0139\n",
            "12 episodes - episode_reward: 12.833 [6.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.523 - mean_q: 0.630 - mean_eps: 0.429 - ale.lives: 1.992\n",
            "\n",
            "Interval 65 (640000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0147\n",
            "10 episodes - episode_reward: 14.300 [5.000, 25.000] - loss: 0.007 - mean_absolute_error: 0.526 - mean_q: 0.638 - mean_eps: 0.419 - ale.lives: 2.104\n",
            "\n",
            "Interval 66 (650000 steps performed)\n",
            "10000/10000 [==============================] - 100s 10ms/step - reward: 0.0173\n",
            "13 episodes - episode_reward: 13.077 [7.000, 20.000] - loss: 0.007 - mean_absolute_error: 0.531 - mean_q: 0.640 - mean_eps: 0.411 - ale.lives: 1.951\n",
            "\n",
            "Interval 67 (660000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0146\n",
            "11 episodes - episode_reward: 13.091 [10.000, 16.000] - loss: 0.008 - mean_absolute_error: 0.534 - mean_q: 0.645 - mean_eps: 0.402 - ale.lives: 2.150\n",
            "\n",
            "Interval 68 (670000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0136\n",
            "13 episodes - episode_reward: 11.154 [1.000, 21.000] - loss: 0.007 - mean_absolute_error: 0.542 - mean_q: 0.653 - mean_eps: 0.393 - ale.lives: 1.961\n",
            "\n",
            "Interval 69 (680000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0148\n",
            "12 episodes - episode_reward: 12.000 [6.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.538 - mean_q: 0.650 - mean_eps: 0.384 - ale.lives: 2.037\n",
            "\n",
            "Interval 70 (690000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0150\n",
            "12 episodes - episode_reward: 12.417 [8.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.552 - mean_q: 0.668 - mean_eps: 0.375 - ale.lives: 2.018\n",
            "\n",
            "Interval 71 (700000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0141\n",
            "12 episodes - episode_reward: 11.417 [6.000, 16.000] - loss: 0.007 - mean_absolute_error: 0.564 - mean_q: 0.682 - mean_eps: 0.365 - ale.lives: 1.849\n",
            "\n",
            "Interval 72 (710000 steps performed)\n",
            "10000/10000 [==============================] - 109s 11ms/step - reward: 0.0159\n",
            "10 episodes - episode_reward: 16.400 [7.000, 28.000] - loss: 0.007 - mean_absolute_error: 0.570 - mean_q: 0.689 - mean_eps: 0.357 - ale.lives: 2.108\n",
            "\n",
            "Interval 73 (720000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0154\n",
            "12 episodes - episode_reward: 13.250 [4.000, 24.000] - loss: 0.006 - mean_absolute_error: 0.570 - mean_q: 0.688 - mean_eps: 0.348 - ale.lives: 1.945\n",
            "\n",
            "Interval 74 (730000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0143\n",
            "12 episodes - episode_reward: 10.833 [2.000, 22.000] - loss: 0.008 - mean_absolute_error: 0.570 - mean_q: 0.688 - mean_eps: 0.338 - ale.lives: 1.999\n",
            "\n",
            "Interval 75 (740000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0138\n",
            "14 episodes - episode_reward: 10.786 [7.000, 18.000] - loss: 0.007 - mean_absolute_error: 0.580 - mean_q: 0.699 - mean_eps: 0.330 - ale.lives: 2.136\n",
            "\n",
            "Interval 76 (750000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0144\n",
            "11 episodes - episode_reward: 12.727 [6.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.588 - mean_q: 0.710 - mean_eps: 0.321 - ale.lives: 2.047\n",
            "\n",
            "Interval 77 (760000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0165\n",
            "11 episodes - episode_reward: 15.000 [9.000, 25.000] - loss: 0.009 - mean_absolute_error: 0.605 - mean_q: 0.730 - mean_eps: 0.311 - ale.lives: 1.833\n",
            "\n",
            "Interval 78 (770000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0149\n",
            "11 episodes - episode_reward: 13.909 [9.000, 23.000] - loss: 0.006 - mean_absolute_error: 0.604 - mean_q: 0.729 - mean_eps: 0.303 - ale.lives: 1.916\n",
            "\n",
            "Interval 79 (780000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0140\n",
            "12 episodes - episode_reward: 11.167 [2.000, 16.000] - loss: 0.008 - mean_absolute_error: 0.607 - mean_q: 0.732 - mean_eps: 0.294 - ale.lives: 2.086\n",
            "\n",
            "Interval 80 (790000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0125\n",
            "14 episodes - episode_reward: 9.071 [2.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.609 - mean_q: 0.735 - mean_eps: 0.284 - ale.lives: 2.018\n",
            "\n",
            "Interval 81 (800000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0122\n",
            "12 episodes - episode_reward: 9.333 [4.000, 14.000] - loss: 0.007 - mean_absolute_error: 0.610 - mean_q: 0.736 - mean_eps: 0.276 - ale.lives: 1.968\n",
            "\n",
            "Interval 82 (810000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0128\n",
            "13 episodes - episode_reward: 10.846 [5.000, 17.000] - loss: 0.007 - mean_absolute_error: 0.616 - mean_q: 0.744 - mean_eps: 0.267 - ale.lives: 1.884\n",
            "\n",
            "Interval 83 (820000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0129\n",
            "12 episodes - episode_reward: 10.250 [3.000, 25.000] - loss: 0.007 - mean_absolute_error: 0.620 - mean_q: 0.749 - mean_eps: 0.257 - ale.lives: 2.142\n",
            "\n",
            "Interval 84 (830000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0141\n",
            "10 episodes - episode_reward: 13.400 [7.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.626 - mean_q: 0.755 - mean_eps: 0.249 - ale.lives: 1.936\n",
            "\n",
            "Interval 85 (840000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0136\n",
            "11 episodes - episode_reward: 13.455 [6.000, 24.000] - loss: 0.007 - mean_absolute_error: 0.627 - mean_q: 0.756 - mean_eps: 0.240 - ale.lives: 1.929\n",
            "\n",
            "Interval 86 (850000 steps performed)\n",
            "10000/10000 [==============================] - 109s 11ms/step - reward: 0.0127\n",
            "10 episodes - episode_reward: 12.700 [10.000, 16.000] - loss: 0.006 - mean_absolute_error: 0.639 - mean_q: 0.771 - mean_eps: 0.230 - ale.lives: 1.887\n",
            "\n",
            "Interval 87 (860000 steps performed)\n",
            "10000/10000 [==============================] - 101s 10ms/step - reward: 0.0144\n",
            "11 episodes - episode_reward: 12.727 [4.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.647 - mean_q: 0.779 - mean_eps: 0.222 - ale.lives: 1.950\n",
            "\n",
            "Interval 88 (870000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0123\n",
            "11 episodes - episode_reward: 11.182 [6.000, 16.000] - loss: 0.007 - mean_absolute_error: 0.653 - mean_q: 0.787 - mean_eps: 0.213 - ale.lives: 1.870\n",
            "\n",
            "Interval 89 (880000 steps performed)\n",
            "10000/10000 [==============================] - 104s 10ms/step - reward: 0.0136\n",
            "11 episodes - episode_reward: 12.091 [6.000, 26.000] - loss: 0.008 - mean_absolute_error: 0.659 - mean_q: 0.795 - mean_eps: 0.203 - ale.lives: 2.068\n",
            "\n",
            "Interval 90 (890000 steps performed)\n",
            "10000/10000 [==============================] - 106s 11ms/step - reward: 0.0155\n",
            "12 episodes - episode_reward: 12.750 [6.000, 21.000] - loss: 0.007 - mean_absolute_error: 0.650 - mean_q: 0.782 - mean_eps: 0.195 - ale.lives: 2.021\n",
            "\n",
            "Interval 91 (900000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0137\n",
            "10 episodes - episode_reward: 14.800 [10.000, 22.000] - loss: 0.007 - mean_absolute_error: 0.658 - mean_q: 0.794 - mean_eps: 0.186 - ale.lives: 1.969\n",
            "\n",
            "Interval 92 (910000 steps performed)\n",
            "10000/10000 [==============================] - 103s 10ms/step - reward: 0.0134\n",
            "9 episodes - episode_reward: 13.667 [3.000, 26.000] - loss: 0.008 - mean_absolute_error: 0.669 - mean_q: 0.807 - mean_eps: 0.176 - ale.lives: 1.919\n",
            "\n",
            "Interval 93 (920000 steps performed)\n",
            "10000/10000 [==============================] - 105s 11ms/step - reward: 0.0135\n",
            "11 episodes - episode_reward: 12.727 [3.000, 25.000] - loss: 0.008 - mean_absolute_error: 0.674 - mean_q: 0.813 - mean_eps: 0.168 - ale.lives: 2.036\n",
            "\n",
            "Interval 94 (930000 steps performed)\n",
            "10000/10000 [==============================] - 107s 11ms/step - reward: 0.0123\n",
            "12 episodes - episode_reward: 10.000 [5.000, 14.000] - loss: 0.007 - mean_absolute_error: 0.691 - mean_q: 0.833 - mean_eps: 0.159 - ale.lives: 2.072\n",
            "\n",
            "Interval 95 (940000 steps performed)\n",
            "10000/10000 [==============================] - 99s 10ms/step - reward: 0.0131\n",
            "11 episodes - episode_reward: 11.818 [6.000, 17.000] - loss: 0.007 - mean_absolute_error: 0.711 - mean_q: 0.859 - mean_eps: 0.149 - ale.lives: 2.018\n",
            "\n",
            "Interval 96 (950000 steps performed)\n",
            "10000/10000 [==============================] - 102s 10ms/step - reward: 0.0129\n",
            "12 episodes - episode_reward: 11.000 [2.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.720 - mean_q: 0.869 - mean_eps: 0.141 - ale.lives: 2.005\n",
            "\n",
            "Interval 97 (960000 steps performed)\n",
            "10000/10000 [==============================] - 97s 10ms/step - reward: 0.0154\n",
            "11 episodes - episode_reward: 13.636 [4.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.734 - mean_q: 0.885 - mean_eps: 0.132 - ale.lives: 2.088\n",
            "\n",
            "Interval 98 (970000 steps performed)\n",
            "10000/10000 [==============================] - 98s 10ms/step - reward: 0.0163\n",
            "12 episodes - episode_reward: 13.833 [6.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.743 - mean_q: 0.898 - mean_eps: 0.122 - ale.lives: 2.044\n",
            "\n",
            "Interval 99 (980000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0139\n",
            "10 episodes - episode_reward: 13.400 [4.000, 25.000] - loss: 0.008 - mean_absolute_error: 0.753 - mean_q: 0.907 - mean_eps: 0.114 - ale.lives: 1.991\n",
            "\n",
            "Interval 100 (990000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0114\n",
            "10 episodes - episode_reward: 12.100 [5.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.756 - mean_q: 0.912 - mean_eps: 0.105 - ale.lives: 2.044\n",
            "\n",
            "Interval 101 (1000000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0108\n",
            "13 episodes - episode_reward: 8.769 [5.000, 13.000] - loss: 0.007 - mean_absolute_error: 0.758 - mean_q: 0.913 - mean_eps: 0.100 - ale.lives: 1.971\n",
            "\n",
            "Interval 102 (1010000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0153\n",
            "11 episodes - episode_reward: 13.909 [7.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.751 - mean_q: 0.905 - mean_eps: 0.100 - ale.lives: 1.980\n",
            "\n",
            "Interval 103 (1020000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0160\n",
            "10 episodes - episode_reward: 16.000 [3.000, 30.000] - loss: 0.009 - mean_absolute_error: 0.756 - mean_q: 0.912 - mean_eps: 0.100 - ale.lives: 2.078\n",
            "\n",
            "Interval 104 (1030000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0141\n",
            "11 episodes - episode_reward: 11.727 [4.000, 16.000] - loss: 0.007 - mean_absolute_error: 0.758 - mean_q: 0.915 - mean_eps: 0.100 - ale.lives: 1.997\n",
            "\n",
            "Interval 105 (1040000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0131\n",
            "12 episodes - episode_reward: 11.000 [5.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.767 - mean_q: 0.923 - mean_eps: 0.100 - ale.lives: 2.055\n",
            "\n",
            "Interval 106 (1050000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0111\n",
            "13 episodes - episode_reward: 9.154 [5.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.778 - mean_q: 0.938 - mean_eps: 0.100 - ale.lives: 2.001\n",
            "\n",
            "Interval 107 (1060000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0107\n",
            "13 episodes - episode_reward: 7.385 [3.000, 11.000] - loss: 0.007 - mean_absolute_error: 0.774 - mean_q: 0.932 - mean_eps: 0.100 - ale.lives: 1.982\n",
            "\n",
            "Interval 108 (1070000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0106\n",
            "10 episodes - episode_reward: 11.900 [3.000, 20.000] - loss: 0.009 - mean_absolute_error: 0.789 - mean_q: 0.949 - mean_eps: 0.100 - ale.lives: 1.891\n",
            "\n",
            "Interval 109 (1080000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0107\n",
            "10 episodes - episode_reward: 9.700 [4.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.796 - mean_q: 0.957 - mean_eps: 0.100 - ale.lives: 1.891\n",
            "\n",
            "Interval 110 (1090000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0151\n",
            "11 episodes - episode_reward: 13.818 [2.000, 22.000] - loss: 0.009 - mean_absolute_error: 0.796 - mean_q: 0.960 - mean_eps: 0.100 - ale.lives: 1.893\n",
            "\n",
            "Interval 111 (1100000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0158\n",
            "12 episodes - episode_reward: 13.000 [6.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.807 - mean_q: 0.974 - mean_eps: 0.100 - ale.lives: 2.011\n",
            "\n",
            "Interval 112 (1110000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0110\n",
            "11 episodes - episode_reward: 10.909 [3.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.827 - mean_q: 0.997 - mean_eps: 0.100 - ale.lives: 2.055\n",
            "\n",
            "Interval 113 (1120000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0126\n",
            "12 episodes - episode_reward: 9.750 [1.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.822 - mean_q: 0.989 - mean_eps: 0.100 - ale.lives: 2.018\n",
            "\n",
            "Interval 114 (1130000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0136\n",
            "9 episodes - episode_reward: 14.778 [7.000, 21.000] - loss: 0.008 - mean_absolute_error: 0.822 - mean_q: 0.991 - mean_eps: 0.100 - ale.lives: 1.819\n",
            "\n",
            "Interval 115 (1140000 steps performed)\n",
            "10000/10000 [==============================] - 95s 9ms/step - reward: 0.0121\n",
            "11 episodes - episode_reward: 11.727 [4.000, 20.000] - loss: 0.007 - mean_absolute_error: 0.823 - mean_q: 0.993 - mean_eps: 0.100 - ale.lives: 1.905\n",
            "\n",
            "Interval 116 (1150000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0130\n",
            "11 episodes - episode_reward: 11.182 [6.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.828 - mean_q: 0.999 - mean_eps: 0.100 - ale.lives: 1.980\n",
            "\n",
            "Interval 117 (1160000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0108\n",
            "11 episodes - episode_reward: 9.636 [3.000, 17.000] - loss: 0.008 - mean_absolute_error: 0.825 - mean_q: 0.994 - mean_eps: 0.100 - ale.lives: 1.967\n",
            "\n",
            "Interval 118 (1170000 steps performed)\n",
            "10000/10000 [==============================] - 92s 9ms/step - reward: 0.0155\n",
            "11 episodes - episode_reward: 15.182 [6.000, 30.000] - loss: 0.007 - mean_absolute_error: 0.831 - mean_q: 1.002 - mean_eps: 0.100 - ale.lives: 1.965\n",
            "\n",
            "Interval 119 (1180000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0151\n",
            "10 episodes - episode_reward: 14.400 [8.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.821 - mean_q: 0.990 - mean_eps: 0.100 - ale.lives: 1.963\n",
            "\n",
            "Interval 120 (1190000 steps performed)\n",
            "10000/10000 [==============================] - 91s 9ms/step - reward: 0.0142\n",
            "11 episodes - episode_reward: 13.273 [5.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.826 - mean_q: 0.997 - mean_eps: 0.100 - ale.lives: 2.063\n",
            "\n",
            "Interval 121 (1200000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0130\n",
            "11 episodes - episode_reward: 12.000 [5.000, 16.000] - loss: 0.008 - mean_absolute_error: 0.819 - mean_q: 0.987 - mean_eps: 0.100 - ale.lives: 1.995\n",
            "\n",
            "Interval 122 (1210000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0132\n",
            "10 episodes - episode_reward: 13.400 [10.000, 23.000] - loss: 0.007 - mean_absolute_error: 0.827 - mean_q: 0.998 - mean_eps: 0.100 - ale.lives: 1.934\n",
            "\n",
            "Interval 123 (1220000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0134\n",
            "12 episodes - episode_reward: 10.583 [2.000, 19.000] - loss: 0.008 - mean_absolute_error: 0.830 - mean_q: 1.000 - mean_eps: 0.100 - ale.lives: 2.117\n",
            "\n",
            "Interval 124 (1230000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0126\n",
            "12 episodes - episode_reward: 10.583 [3.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.841 - mean_q: 1.016 - mean_eps: 0.100 - ale.lives: 2.044\n",
            "\n",
            "Interval 125 (1240000 steps performed)\n",
            "10000/10000 [==============================] - 93s 9ms/step - reward: 0.0142\n",
            "9 episodes - episode_reward: 15.778 [4.000, 23.000] - loss: 0.009 - mean_absolute_error: 0.851 - mean_q: 1.026 - mean_eps: 0.100 - ale.lives: 1.805\n",
            "\n",
            "Interval 126 (1250000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0139\n",
            "11 episodes - episode_reward: 13.000 [6.000, 17.000] - loss: 0.009 - mean_absolute_error: 0.851 - mean_q: 1.028 - mean_eps: 0.100 - ale.lives: 1.962\n",
            "\n",
            "Interval 127 (1260000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0130\n",
            "10 episodes - episode_reward: 12.400 [5.000, 18.000] - loss: 0.008 - mean_absolute_error: 0.861 - mean_q: 1.037 - mean_eps: 0.100 - ale.lives: 1.981\n",
            "\n",
            "Interval 128 (1270000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0142\n",
            "10 episodes - episode_reward: 13.800 [8.000, 20.000] - loss: 0.008 - mean_absolute_error: 0.870 - mean_q: 1.049 - mean_eps: 0.100 - ale.lives: 2.030\n",
            "\n",
            "Interval 129 (1280000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0137\n",
            "11 episodes - episode_reward: 12.636 [5.000, 22.000] - loss: 0.008 - mean_absolute_error: 0.875 - mean_q: 1.057 - mean_eps: 0.100 - ale.lives: 1.911\n",
            "\n",
            "Interval 130 (1290000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0159\n",
            "11 episodes - episode_reward: 14.909 [6.000, 20.000] - loss: 0.007 - mean_absolute_error: 0.883 - mean_q: 1.066 - mean_eps: 0.100 - ale.lives: 2.096\n",
            "\n",
            "Interval 131 (1300000 steps performed)\n",
            "10000/10000 [==============================] - 94s 9ms/step - reward: 0.0148\n",
            "9 episodes - episode_reward: 16.889 [7.000, 24.000] - loss: 0.008 - mean_absolute_error: 0.893 - mean_q: 1.077 - mean_eps: 0.100 - ale.lives: 1.911\n",
            "\n",
            "Interval 132 (1310000 steps performed)\n",
            "10000/10000 [==============================] - 95s 9ms/step - reward: 0.0112\n",
            "11 episodes - episode_reward: 10.455 [4.000, 19.000] - loss: 0.009 - mean_absolute_error: 0.905 - mean_q: 1.091 - mean_eps: 0.100 - ale.lives: 2.105\n",
            "\n",
            "Interval 133 (1320000 steps performed)\n",
            "10000/10000 [==============================] - 96s 10ms/step - reward: 0.0136\n",
            "12 episodes - episode_reward: 11.333 [3.000, 25.000] - loss: 0.009 - mean_absolute_error: 0.922 - mean_q: 1.110 - mean_eps: 0.100 - ale.lives: 1.919\n",
            "\n",
            "Interval 134 (1330000 steps performed)\n",
            " 6139/10000 [=================>............] - ETA: 36s - reward: 0.0112"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh73Zryr9IRv"
      },
      "source": [
        "# Testing part to calculate the mean reward\n",
        "weights_filename = 'dqn_{}_weights_1500000.h5'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=10, visualize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsXA-F6GW3UU"
      },
      "source": [
        "# Testing part to calculate the mean reward\n",
        "weights_filename = 'dqn_{}_weights_1750000.h5'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=50, visualize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvm7X4_KuxBJ"
      },
      "source": [
        ""
      ]
    }
  ]
}